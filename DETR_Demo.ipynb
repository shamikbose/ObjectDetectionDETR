{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DETR_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gwNY-Q--ftt"
      },
      "source": [
        "## This is a demo notebook showing how we can use the Object Detection and Recognition from Facebook AI Research (FAIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1Y0ToD1HgDo"
      },
      "source": [
        "Import required libraries and download the model from PyTorch hub. There are lots of models to choose from. To run inference, set *pretrained=True*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLOANYD4iizD"
      },
      "source": [
        "import torch as th\n",
        "import torchvision.transforms as T\n",
        "import requests\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import ipywidgets as widgets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itNIbKsCi2am"
      },
      "source": [
        "model = th.hub.load('facebookresearch/detr', 'detr_resnet101', pretrained=True)\n",
        "model.eval()\n",
        "model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmk9nyN_H3mb"
      },
      "source": [
        "Run basic compositions are required for ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrRvnPX_kg-B"
      },
      "source": [
        "# standard PyTorch mean-std input image normalization\n",
        "transform = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "CLASSES = [\n",
        "    'N/A', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A',\n",
        "    'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse',\n",
        "    'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack',\n",
        "    'umbrella', 'N/A', 'N/A', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis',\n",
        "    'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
        "    'skateboard', 'surfboard', 'tennis racket', 'bottle', 'N/A', 'wine glass',\n",
        "    'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
        "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake',\n",
        "    'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
        "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
        "    'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A',\n",
        "    'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
        "    'toothbrush'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu4X46pJHVmW"
      },
      "source": [
        "Get user input for image search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD63cAbq5rPX"
      },
      "source": [
        "print(\"Enter up to 5 comma separated search terms\")\r\n",
        "search_terms=widgets.Textarea(\r\n",
        "    value=\"\",\r\n",
        "    description=\"\"\r\n",
        ")\r\n",
        "display(search_terms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATq9eBYx7Q9x"
      },
      "source": [
        "search_terms=search_terms.value.split(\",\")\r\n",
        "if len(search_terms)>5:\r\n",
        "  search_terms=search_terms[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m05MDMVIZfAZ"
      },
      "source": [
        "Set up code to return images using the Unsplash API. \r\n",
        "\r\n",
        "We save the top search result and its description from the json response"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhhdiqQ5i99U"
      },
      "source": [
        "height, width=800, 600\r\n",
        "#Sign up for an unsplash API here: \r\n",
        "#https://unsplash.com/oauth/applications\r\n",
        "access_key=\"<Access Key here>\"\r\n",
        "base_url=\"https://api.unsplash.com/search/photos?query=\"\r\n",
        "client_id_str=\"&client_id=\"+access_key\r\n",
        "keywords=search_terms\r\n",
        "imgs=[]\r\n",
        "img_descs=[]\r\n",
        "for keyword in keywords:\r\n",
        "  query=base_url+keyword+client_id_str\r\n",
        "  r=requests.get(query)\r\n",
        "  img_url=r.json()['results'][0]['urls']['raw']\r\n",
        "  img_desc=r.json()['results'][0]['description']\r\n",
        "  img = Image.open(requests.get(img_url, stream=True).raw).resize((height, width)).convert('RGB')\r\n",
        "  imgs.append(img)\r\n",
        "  img_descs.append(img_desc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhWKbU5ENpRM"
      },
      "source": [
        "This is the cell where we run inference on the images gathered from Unsplash. The steps are as follows:\r\n",
        "1. Make a copy of the image\r\n",
        "2. Set model to eval mode by setting *no_grad*\r\n",
        "3. Forward propagate image through the model. Output includes:\r\n",
        " - Probabilities of classes\r\n",
        " - Bounding boxes for those classes\r\n",
        "4. We pick the top *objects_to_detect* values from the outputs and their args and plot the boxes and labels on the copy of the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBkWg2-40_nR"
      },
      "source": [
        "objects_to_detect=3\r\n",
        "from PIL import ImageFont\r\n",
        "# fnt = ImageFont.truetype(\"Pillow/Tests/fonts/FreeMono.ttf\", 10)\r\n",
        "for idx, img in enumerate(imgs):\r\n",
        "  im2 = img.copy()\r\n",
        "  drw = ImageDraw.Draw(im2)\r\n",
        "  img_tens = transform(img).unsqueeze(0).cuda()\r\n",
        "  with th.no_grad():\r\n",
        "    output = model(img_tens)\r\n",
        "  pred_logits=output['pred_logits'][0][:, :len(CLASSES)]\r\n",
        "  pred_boxes=output['pred_boxes'][0]\r\n",
        "  max_output = pred_logits.softmax(-1).max(-1)\r\n",
        "  topk = max_output.values.topk(objects_to_detect)\r\n",
        "\r\n",
        "  pred_logits = pred_logits[topk.indices]\r\n",
        "  pred_boxes = pred_boxes[topk.indices]\r\n",
        "  for logits, box in zip(pred_logits, pred_boxes):\r\n",
        "    cls = logits.argmax()\r\n",
        "    if cls >= len(CLASSES):\r\n",
        "      continue\r\n",
        "    label = CLASSES[cls]\r\n",
        "    box = box.cpu() * th.Tensor([height, width, height, width])\r\n",
        "    x, y, w, h = box\r\n",
        "    x0, x1 = x-w//2, x+w//2\r\n",
        "    y0, y1 = y-h//2, y+h//2\r\n",
        "    drw.rectangle([x0, y0, x1, y1], outline='black', width=5)\r\n",
        "    label_pos=(x0, y0-15)\r\n",
        "    drw.text(label_pos, label, fill='red')\r\n",
        "  print(img_descs[idx])\r\n",
        "  display(im2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbu7xEggbFQK"
      },
      "source": [
        "To Do:\r\n",
        "1. Return logits above a certain confidence threshold only\r\n",
        "2. Find similarity between image tags and detected objects\r\n",
        "3. Automatically add missing tags if confidence threshold is above a certain value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0xWMD1tbbxo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}